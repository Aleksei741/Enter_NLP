{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запустить seq2seq, seq2seq с внимаием для перевода русских слов + описать наблюдения по качеству"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 60\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "data_path = 'data/rus-eng/rus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем из текстов токены и делаем pne-hot вектора на каждый токен\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    \n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 1.1247 - accuracy: 0.7742 - val_loss: 0.9280 - val_accuracy: 0.7592\n",
      "Epoch 2/60\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.7317 - accuracy: 0.8035 - val_loss: 0.7834 - val_accuracy: 0.7927\n",
      "Epoch 3/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.7264 - accuracy: 0.8107 - val_loss: 0.7434 - val_accuracy: 0.8062\n",
      "Epoch 4/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.6114 - accuracy: 0.8367 - val_loss: 0.6717 - val_accuracy: 0.8136\n",
      "Epoch 5/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.5610 - accuracy: 0.8443 - val_loss: 0.6352 - val_accuracy: 0.8200\n",
      "Epoch 6/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.5321 - accuracy: 0.8495 - val_loss: 0.6057 - val_accuracy: 0.8271\n",
      "Epoch 7/60\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.5120 - accuracy: 0.8539 - val_loss: 0.5951 - val_accuracy: 0.8281\n",
      "Epoch 8/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.4959 - accuracy: 0.8576 - val_loss: 0.5761 - val_accuracy: 0.8335\n",
      "Epoch 9/60\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.4819 - accuracy: 0.8608 - val_loss: 0.5622 - val_accuracy: 0.8366\n",
      "Epoch 10/60\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.4701 - accuracy: 0.8636 - val_loss: 0.5535 - val_accuracy: 0.8383\n",
      "Epoch 11/60\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.4601 - accuracy: 0.8655 - val_loss: 0.5424 - val_accuracy: 0.8430\n",
      "Epoch 12/60\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.4505 - accuracy: 0.8681 - val_loss: 0.5301 - val_accuracy: 0.8445\n",
      "Epoch 13/60\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.4410 - accuracy: 0.8710 - val_loss: 0.5244 - val_accuracy: 0.8463\n",
      "Epoch 14/60\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.4323 - accuracy: 0.8732 - val_loss: 0.5140 - val_accuracy: 0.8494\n",
      "Epoch 15/60\n",
      "125/125 [==============================] - 4s 33ms/step - loss: 0.4229 - accuracy: 0.8759 - val_loss: 0.5052 - val_accuracy: 0.8526\n",
      "Epoch 16/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.4149 - accuracy: 0.8782 - val_loss: 0.4971 - val_accuracy: 0.8562\n",
      "Epoch 17/60\n",
      "125/125 [==============================] - 4s 28ms/step - loss: 0.4062 - accuracy: 0.8806 - val_loss: 0.4916 - val_accuracy: 0.8573\n",
      "Epoch 18/60\n",
      "125/125 [==============================] - 4s 33ms/step - loss: 0.3980 - accuracy: 0.8833 - val_loss: 0.4891 - val_accuracy: 0.8585\n",
      "Epoch 19/60\n",
      "125/125 [==============================] - 4s 32ms/step - loss: 0.3893 - accuracy: 0.8857 - val_loss: 0.4812 - val_accuracy: 0.8604\n",
      "Epoch 20/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.3818 - accuracy: 0.8882 - val_loss: 0.4745 - val_accuracy: 0.8615\n",
      "Epoch 21/60\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.3740 - accuracy: 0.8903 - val_loss: 0.4680 - val_accuracy: 0.8648\n",
      "Epoch 22/60\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.3662 - accuracy: 0.8930 - val_loss: 0.4661 - val_accuracy: 0.8663\n",
      "Epoch 23/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.3591 - accuracy: 0.8948 - val_loss: 0.4590 - val_accuracy: 0.8685\n",
      "Epoch 24/60\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.3523 - accuracy: 0.8973 - val_loss: 0.4556 - val_accuracy: 0.8685\n",
      "Epoch 25/60\n",
      "125/125 [==============================] - 3s 28ms/step - loss: 0.3448 - accuracy: 0.8992 - val_loss: 0.4509 - val_accuracy: 0.8717\n",
      "Epoch 26/60\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.3375 - accuracy: 0.9015 - val_loss: 0.4483 - val_accuracy: 0.8720\n",
      "Epoch 27/60\n",
      "125/125 [==============================] - 3s 28ms/step - loss: 0.3303 - accuracy: 0.9034 - val_loss: 0.4447 - val_accuracy: 0.8735\n",
      "Epoch 28/60\n",
      "125/125 [==============================] - 4s 28ms/step - loss: 0.3239 - accuracy: 0.9053 - val_loss: 0.4401 - val_accuracy: 0.8749\n",
      "Epoch 29/60\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.3168 - accuracy: 0.9074 - val_loss: 0.4394 - val_accuracy: 0.8751\n",
      "Epoch 30/60\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.3100 - accuracy: 0.9093 - val_loss: 0.4334 - val_accuracy: 0.8771\n",
      "Epoch 31/60\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.3015 - accuracy: 0.9120 - val_loss: 0.4324 - val_accuracy: 0.8776\n",
      "Epoch 32/60\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.2948 - accuracy: 0.9139 - val_loss: 0.4307 - val_accuracy: 0.8780\n",
      "Epoch 33/60\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.2880 - accuracy: 0.9155 - val_loss: 0.4283 - val_accuracy: 0.8782\n",
      "Epoch 34/60\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.2816 - accuracy: 0.9174 - val_loss: 0.4272 - val_accuracy: 0.8795\n",
      "Epoch 35/60\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.2747 - accuracy: 0.9194 - val_loss: 0.4239 - val_accuracy: 0.8805\n",
      "Epoch 36/60\n",
      "125/125 [==============================] - 4s 34ms/step - loss: 0.2671 - accuracy: 0.9217 - val_loss: 0.4244 - val_accuracy: 0.8823\n",
      "Epoch 37/60\n",
      "125/125 [==============================] - 3s 28ms/step - loss: 0.2609 - accuracy: 0.9233 - val_loss: 0.4285 - val_accuracy: 0.8808\n",
      "Epoch 38/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.2541 - accuracy: 0.9251 - val_loss: 0.4261 - val_accuracy: 0.8819\n",
      "Epoch 39/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.2475 - accuracy: 0.9272 - val_loss: 0.4262 - val_accuracy: 0.8818\n",
      "Epoch 40/60\n",
      "125/125 [==============================] - 4s 28ms/step - loss: 0.2409 - accuracy: 0.9291 - val_loss: 0.4259 - val_accuracy: 0.8829\n",
      "Epoch 41/60\n",
      "125/125 [==============================] - 4s 29ms/step - loss: 0.2352 - accuracy: 0.9309 - val_loss: 0.4247 - val_accuracy: 0.8832\n",
      "Epoch 42/60\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.2293 - accuracy: 0.9323 - val_loss: 0.4238 - val_accuracy: 0.8837\n",
      "Epoch 43/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.2227 - accuracy: 0.9343 - val_loss: 0.4266 - val_accuracy: 0.8842\n",
      "Epoch 44/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.2161 - accuracy: 0.9362 - val_loss: 0.4289 - val_accuracy: 0.8834\n",
      "Epoch 45/60\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.2109 - accuracy: 0.9376 - val_loss: 0.4261 - val_accuracy: 0.8847\n",
      "Epoch 46/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.2065 - accuracy: 0.9391 - val_loss: 0.4308 - val_accuracy: 0.8841\n",
      "Epoch 47/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.1998 - accuracy: 0.9411 - val_loss: 0.4331 - val_accuracy: 0.8852\n",
      "Epoch 48/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.1937 - accuracy: 0.9425 - val_loss: 0.4337 - val_accuracy: 0.8853\n",
      "Epoch 49/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.1885 - accuracy: 0.9441 - val_loss: 0.4371 - val_accuracy: 0.8844\n",
      "Epoch 50/60\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.1841 - accuracy: 0.9454 - val_loss: 0.4399 - val_accuracy: 0.8854\n",
      "Epoch 51/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.1781 - accuracy: 0.9471 - val_loss: 0.4423 - val_accuracy: 0.8850\n",
      "Epoch 52/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.1730 - accuracy: 0.9483 - val_loss: 0.4470 - val_accuracy: 0.8848\n",
      "Epoch 53/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.1679 - accuracy: 0.9501 - val_loss: 0.4491 - val_accuracy: 0.8847\n",
      "Epoch 54/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.1639 - accuracy: 0.9509 - val_loss: 0.4518 - val_accuracy: 0.8849\n",
      "Epoch 55/60\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.1583 - accuracy: 0.9525 - val_loss: 0.4542 - val_accuracy: 0.8857\n",
      "Epoch 56/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.1549 - accuracy: 0.9536 - val_loss: 0.4629 - val_accuracy: 0.8849\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 4s 31ms/step - loss: 0.1505 - accuracy: 0.9547 - val_loss: 0.4630 - val_accuracy: 0.8853\n",
      "Epoch 58/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.1458 - accuracy: 0.9562 - val_loss: 0.4639 - val_accuracy: 0.8850\n",
      "Epoch 59/60\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 0.1419 - accuracy: 0.9574 - val_loss: 0.4675 - val_accuracy: 0.8863\n",
      "Epoch 60/60\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.1394 - accuracy: 0.9577 - val_loss: 0.4709 - val_accuracy: 0.8852\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Иди.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Иди.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Иди.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здрасте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здрасте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здрасте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здрасте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здрасте.\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Беги!\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Беги!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(10):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow.compat.v1 as tf\n",
    "data_path = 'data/rus-eng/rus.txt'\n",
    "num_samples = 10000\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "def preprocess_sentence_rus(w):\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^а-яА-Я?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(preprocess_sentence(input_text))\n",
    "    target_texts.append(preprocess_sentence_rus(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
    "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "    \n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 1.6721\n",
      "Epoch 2 Loss 1.2604\n",
      "Epoch 3 Loss 1.0817\n",
      "Epoch 4 Loss 0.9324\n",
      "Epoch 5 Loss 0.8050\n",
      "Epoch 6 Loss 0.6805\n",
      "Epoch 7 Loss 0.5662\n",
      "Epoch 8 Loss 0.4664\n",
      "Epoch 9 Loss 0.3820\n",
      "Epoch 10 Loss 0.3206\n",
      "Epoch 11 Loss 0.2760\n",
      "Epoch 12 Loss 0.2418\n",
      "Epoch 13 Loss 0.2177\n",
      "Epoch 14 Loss 0.2002\n",
      "Epoch 15 Loss 0.1866\n",
      "Epoch 16 Loss 0.1784\n",
      "Epoch 17 Loss 0.1698\n",
      "Epoch 18 Loss 0.1631\n",
      "Epoch 19 Loss 0.1582\n",
      "Epoch 20 Loss 0.1542\n",
      "Epoch 21 Loss 0.1493\n",
      "Epoch 22 Loss 0.1455\n",
      "Epoch 23 Loss 0.1414\n",
      "Epoch 24 Loss 0.1385\n",
      "Epoch 25 Loss 0.1368\n",
      "Epoch 26 Loss 0.1345\n",
      "Epoch 27 Loss 0.1332\n",
      "Epoch 28 Loss 0.1321\n",
      "Epoch 29 Loss 0.1305\n",
      "Epoch 30 Loss 0.1283\n",
      "Epoch 31 Loss 0.1274\n",
      "Epoch 32 Loss 0.1263\n",
      "Epoch 33 Loss 0.1260\n",
      "Epoch 34 Loss 0.1290\n",
      "Epoch 35 Loss 0.1242\n",
      "Epoch 36 Loss 0.1217\n",
      "Epoch 37 Loss 0.1224\n",
      "Epoch 38 Loss 0.1193\n",
      "Epoch 39 Loss 0.1184\n",
      "Epoch 40 Loss 0.1177\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "for epoch in range(EPOCHS):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> Go . <end>',\n",
       " '<start> Go . <end>',\n",
       " '<start> Go . <end>',\n",
       " '<start> Hi . <end>',\n",
       " '<start> Hi . <end>',\n",
       " '<start> Hi . <end>',\n",
       " '<start> Hi . <end>',\n",
       " '<start> Hi . <end>',\n",
       " '<start> Run ! <end>',\n",
       " '<start> Run ! <end>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> Марш ! <end>',\n",
       " '<start> Иди . <end>',\n",
       " '<start> Идите . <end>',\n",
       " '<start> Здравствуйте . <end>',\n",
       " '<start> Привет ! <end>',\n",
       " '<start> Хай . <end>',\n",
       " '<start> Здрасте . <end>',\n",
       " '<start> Здоро во ! <end>',\n",
       " '<start> Беги ! <end>',\n",
       " '<start> Бегите ! <end>']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые украденные функции для оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    #ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    #ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "    \n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> good morning . <end>\n",
      "Predicted translation: доброе утро . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " translate(u'good morning .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все работает, но если бить без точки то некоректно переводит (это из-за обучающего dataseta. надобы поправить, но...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## переделать генерацию текста по символам в генерацию по словам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'evgenyi_onegin.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 286984 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Александр Сергеевич Пушкин\n",
      "\n",
      "                                Евгений Онегин\n",
      "                                Роман в стихах\n",
      "\n",
      "                        Не мысля гордый свет забавить,\n",
      "                        Вниманье дружбы возлюбя,\n",
      "                       \n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mas = re.findall(r',|\\.|\\s|[а-яА-Я]+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9098 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text_mas))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "word2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2word = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([word2idx[c] for c in text_mas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   1,    1,    1,    1,    1,    1,  925,    1, 5061,    1, 3139,\n",
       "           1, 7280,    1, 3752,    2,    0,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1]),\n",
       " [' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  'Не',\n",
       "  ' ',\n",
       "  'мысля',\n",
       "  ' ',\n",
       "  'гордый',\n",
       "  ' ',\n",
       "  'свет',\n",
       "  ' ',\n",
       "  'забавить',\n",
       "  ',',\n",
       "  '\\n',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' '],\n",
       " 195435,\n",
       " 286984)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int[100:140], text_mas[100:140], len(text_as_int), len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Александр\n",
      " \n",
      "Сергеевич\n",
      " \n",
      "Пушкин\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2word[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                                Роман в стихах\\n\\n                   '\n",
      "'     Не мысля гордый свет забавить,\\n                        Вниманье дружбы возлюбя,\\n                        Хотел бы я тебе представить\\n                    '\n",
      "'    Залог достойнее тебя,\\n                        Достойнее души прекрасной,\\n                        Святой исполненной мечты,\\n                        Поэзии живой '\n",
      "'и ясной,\\n                        Высоких дум и простоты\\n                        Но так и быть  рукой пристрастной\\n                        Прими собранье'\n",
      "' пестрых глав,\\n                        Полусмешных, полупечальных,\\n                        Простонародных, идеальных,\\n                        Небрежный плод моих забав,\\n  '\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2word[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                                Роман в стихах\\n\\n                  '\n",
      "Target data: ' Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                                Роман в стихах\\n\\n                   '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2word[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2word[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 9098) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (64, None, 256)           2329088   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (64, None, 1024)          3935232   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (64, None, 9098)          9325450   \n",
      "=================================================================\n",
      "Total params: 15,589,770\n",
      "Trainable params: 15,589,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " '            Любовник Юлии Вольмар,\\n                        МалекАдель и де Линар,\\n                        И Вертер, мученик мятежный,\\n             '\n",
      "\n",
      "Next Char Predictions: \n",
      " 'поблеклыйусыпляюЛеснаяводилРегулклонятшепталадрузьянежныйвышелдетиБалвласыпосетиливпросакнебомзавидимпокойпрадедовнаслажденьембудучиписатьжурчаньеувиделавешниеВозможноразогналиежегодноОчаровательныхПетушковВсюЧужогооблитсанкиОтметкунивыблагосклонныймладойтеперьзлословиемДелилигороюСтаканвсяответДавайсмелыйскукоюсвекровьдавилСадиначалевпервыебогатынемудреномечтаньеглазамразыгранныйнагоняястаринаПриготовляетсябезыменноюнеугомоннотяжбыЗаветныйволжскихГремучийискрамиприемныймужчинамиСказалсупругурытьсяЛинарсвоевольныйвысшембезотрадночиститьвосторговмутнымиокаменетьбьютпылкихпокинутьзевнулстебелекбурюпредсказаньясдуруостротызнанийщадитькняжнывысшийПчелаМладыхужимокбранятИдетДушеньки'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2word[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2word[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 9098)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       9.115717\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "30/30 [==============================] - 22s 749ms/step - loss: 2.7018\n",
      "Epoch 2/60\n",
      "30/30 [==============================] - 22s 730ms/step - loss: 1.6693\n",
      "Epoch 3/60\n",
      "30/30 [==============================] - 22s 741ms/step - loss: 1.6566\n",
      "Epoch 4/60\n",
      "30/30 [==============================] - 23s 760ms/step - loss: 1.6558\n",
      "Epoch 5/60\n",
      "30/30 [==============================] - 23s 768ms/step - loss: 1.6558\n",
      "Epoch 6/60\n",
      "30/30 [==============================] - 23s 776ms/step - loss: 1.6531\n",
      "Epoch 7/60\n",
      "30/30 [==============================] - 23s 780ms/step - loss: 1.6550\n",
      "Epoch 8/60\n",
      "30/30 [==============================] - 23s 780ms/step - loss: 1.6552\n",
      "Epoch 9/60\n",
      "30/30 [==============================] - 24s 797ms/step - loss: 1.6531\n",
      "Epoch 10/60\n",
      "30/30 [==============================] - 24s 785ms/step - loss: 1.6351\n",
      "Epoch 11/60\n",
      "30/30 [==============================] - 24s 791ms/step - loss: 1.5647\n",
      "Epoch 12/60\n",
      "30/30 [==============================] - 24s 801ms/step - loss: 1.4843\n",
      "Epoch 13/60\n",
      "30/30 [==============================] - 24s 790ms/step - loss: 1.4320\n",
      "Epoch 14/60\n",
      "30/30 [==============================] - 24s 795ms/step - loss: 1.3747\n",
      "Epoch 15/60\n",
      "30/30 [==============================] - 24s 797ms/step - loss: 1.3229\n",
      "Epoch 16/60\n",
      "30/30 [==============================] - 24s 798ms/step - loss: 1.2933\n",
      "Epoch 17/60\n",
      "30/30 [==============================] - 24s 798ms/step - loss: 1.2735\n",
      "Epoch 18/60\n",
      "30/30 [==============================] - 24s 804ms/step - loss: 1.2616\n",
      "Epoch 19/60\n",
      "30/30 [==============================] - 24s 808ms/step - loss: 1.2515\n",
      "Epoch 20/60\n",
      "30/30 [==============================] - 24s 802ms/step - loss: 1.2437\n",
      "Epoch 21/60\n",
      "30/30 [==============================] - 24s 796ms/step - loss: 1.2368\n",
      "Epoch 22/60\n",
      "30/30 [==============================] - 25s 847ms/step - loss: 1.2302\n",
      "Epoch 23/60\n",
      "30/30 [==============================] - 26s 856ms/step - loss: 1.2247\n",
      "Epoch 24/60\n",
      "30/30 [==============================] - 26s 852ms/step - loss: 1.2178\n",
      "Epoch 25/60\n",
      "30/30 [==============================] - 25s 839ms/step - loss: 1.2127\n",
      "Epoch 26/60\n",
      "30/30 [==============================] - 25s 822ms/step - loss: 1.2109\n",
      "Epoch 27/60\n",
      "30/30 [==============================] - 25s 840ms/step - loss: 1.2065\n",
      "Epoch 28/60\n",
      "30/30 [==============================] - 25s 839ms/step - loss: 1.1999\n",
      "Epoch 29/60\n",
      "30/30 [==============================] - 25s 832ms/step - loss: 1.2221\n",
      "Epoch 30/60\n",
      "30/30 [==============================] - 25s 821ms/step - loss: 1.5390\n",
      "Epoch 31/60\n",
      "30/30 [==============================] - 25s 821ms/step - loss: 1.3159\n",
      "Epoch 32/60\n",
      "30/30 [==============================] - 25s 821ms/step - loss: 1.2666\n",
      "Epoch 33/60\n",
      "30/30 [==============================] - 25s 818ms/step - loss: 1.2450\n",
      "Epoch 34/60\n",
      "30/30 [==============================] - 25s 827ms/step - loss: 1.2293\n",
      "Epoch 35/60\n",
      "30/30 [==============================] - 25s 819ms/step - loss: 1.2197\n",
      "Epoch 36/60\n",
      "30/30 [==============================] - 24s 815ms/step - loss: 1.2082\n",
      "Epoch 37/60\n",
      "30/30 [==============================] - 25s 821ms/step - loss: 1.1987\n",
      "Epoch 38/60\n",
      "30/30 [==============================] - 25s 828ms/step - loss: 1.1887\n",
      "Epoch 39/60\n",
      "30/30 [==============================] - 25s 828ms/step - loss: 1.1723\n",
      "Epoch 40/60\n",
      "30/30 [==============================] - 25s 836ms/step - loss: 1.1483\n",
      "Epoch 41/60\n",
      "30/30 [==============================] - 25s 821ms/step - loss: 1.1499\n",
      "Epoch 42/60\n",
      "30/30 [==============================] - 25s 820ms/step - loss: 1.1341\n",
      "Epoch 43/60\n",
      "30/30 [==============================] - 25s 822ms/step - loss: 1.1295\n",
      "Epoch 44/60\n",
      "30/30 [==============================] - 25s 824ms/step - loss: 1.1255\n",
      "Epoch 45/60\n",
      "30/30 [==============================] - 25s 830ms/step - loss: 1.1056\n",
      "Epoch 46/60\n",
      "30/30 [==============================] - 25s 828ms/step - loss: 1.0992\n",
      "Epoch 47/60\n",
      "30/30 [==============================] - 25s 834ms/step - loss: 1.0913\n",
      "Epoch 48/60\n",
      "30/30 [==============================] - 25s 827ms/step - loss: 1.0821\n",
      "Epoch 49/60\n",
      "30/30 [==============================] - 26s 875ms/step - loss: 1.0840\n",
      "Epoch 50/60\n",
      "30/30 [==============================] - 25s 823ms/step - loss: 1.0622\n",
      "Epoch 51/60\n",
      "30/30 [==============================] - 25s 825ms/step - loss: 1.0575\n",
      "Epoch 52/60\n",
      "30/30 [==============================] - 25s 829ms/step - loss: 1.0437\n",
      "Epoch 53/60\n",
      "30/30 [==============================] - 25s 828ms/step - loss: 1.0368\n",
      "Epoch 54/60\n",
      "30/30 [==============================] - 25s 832ms/step - loss: 1.0237\n",
      "Epoch 55/60\n",
      "30/30 [==============================] - 25s 818ms/step - loss: 1.0054\n",
      "Epoch 56/60\n",
      "30/30 [==============================] - 24s 815ms/step - loss: 1.0178\n",
      "Epoch 57/60\n",
      "30/30 [==============================] - 25s 817ms/step - loss: 0.9753\n",
      "Epoch 58/60\n",
      "30/30 [==============================] - 24s 816ms/step - loss: 0.9737\n",
      "Epoch 59/60\n",
      "30/30 [==============================] - 25s 819ms/step - loss: 0.9463\n",
      "Epoch 60/60\n",
      "30/30 [==============================] - 24s 812ms/step - loss: 0.9115\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints\\\\ckpt_60'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (1, None, 256)            2329088   \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (1, None, 1024)           3935232   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (1, None, 9098)           9325450   \n",
      "=================================================================\n",
      "Total params: 15,589,770\n",
      "Trainable params: 15,589,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 500\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [word2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2word[predicted_id])\n",
    "        \n",
    "    start_string = ''.join(start_string)\n",
    "    return (start_string + ''.join(text_generated))\n",
    "    #return text_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уж месяц был ли, конечно, раскаяньем Расин,\n",
      "             томный пел залу гондоле\n",
      " богу убит\n",
      "             Они, сплетни, стеклянным Киприды,\n",
      "       До глухой, няня, раздетый,\n",
      "           Пойду тошно, которой журналы,\n",
      "              Однако же, скучал, полдень и страданье\n",
      "         с засмеяться наша бане\n",
      "                    Вновь вместе, прощальный кременьплоходомойто же тот, Таня, ль\n",
      "    Забыт. он, многом\n",
      "               Татьяну равнодушных\n",
      "            К Отца неземной,\n",
      "       То мысль слезами небосклоне\n",
      "\n",
      "            Приготовляется дома сонным привета,\n",
      "        Ни цевницы вас привела\n",
      "        Уж их трещитокруженразлучило.\n",
      "\n",
      "               О некогда молчаливом женой.\n",
      "\n",
      "           .\n",
      "\n",
      "       Но вдруг уж знать,\n",
      "              Поутру живо вседневные устала\n",
      "           Держу ждет свет порукой,\n",
      "               ПустыннымА за тайною мадригальных\n",
      "          Он слыхали, блаженные пыльной очах,\n",
      "     Приготовляется молвил искусства,\n",
      "                    Потолковать жил утром модной\n",
      "    нежно уныние..\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=['Уж', ' ', 'месяц', ' ', 'был', ' ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По буквам лучше было"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
